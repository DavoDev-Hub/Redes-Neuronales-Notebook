{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "312d77d8",
   "metadata": {},
   "source": [
    "# Importaciones y configuración básica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd13967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "tf.random.set_seed(7)\n",
    "np.random.seed(7)\n",
    "\n",
    "SEQ_LEN = 20          # longitud de contexto en palabras (antes: contexto en chars)\n",
    "EMBED_DIM = 128\n",
    "RNN_UNITS = 256\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9384ae0",
   "metadata": {},
   "source": [
    "### Cargar texto crudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df2d6bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prologo\n",
      "En 1953, Isaac Asimov publico Segunda Fundación, el tercer libro de la saga de la Fundación (o el decimotercero según otras fuentes, este es un tema de debate). En Segunda Fundacion aparece por primera vez Arkady Darell, uno de los principales personajes de la parte final de la saga. En su primera escena, Arkady, que tiene 14 anos, esta haciendo sus tareas escolares. En concreto, una redaccion que lleva por titulo ?El Futuro del Plan Sheldon?. Para hacer la redacción, Arkady esta utilizando un ?transcriptor?,un dispositivo que convierte su voz en palabras escritas. Este tipo de dispositivo, que para Isaac Asimov era ciencia ficcion en 1953, lo tenemos al alcance de la mano en la mayoria de nuestros smartphones, y el Deep Learning es uno de los responsables de que ya tengamos este tipo de aplicaciones, siendo la tecnologia otro de ellos.En la actualidad disponemos de GPUs (Graphics Processor Units), que solo cuestan alrededor de 100 euros, que estarían en la lista del Top500 hac\n"
     ]
    }
   ],
   "source": [
    "with open('datasets/texto.txt', 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print(raw_text[:1000])  # vistazo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de75a2c6",
   "metadata": {},
   "source": [
    "## Limpieza ligera y normalización (opcional, pero útil para vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e4c14f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prologo en 1953, isaac asimov publico segunda fundación, el tercer libro de la saga de la fundación (o el decimotercero según otras fuentes, este es un tema de debate). en segunda fundacion aparece por primera vez arkady darell, uno de los principales personajes de la parte final de la saga. en su p\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'\\s+', ' ', s)              # colapsa espacios\n",
    "    s = s.replace('“','\"').replace('”','\"').replace('’',\"'\")\n",
    "    s = s.replace('—','-').replace('–','-')\n",
    "    return s.strip()\n",
    "\n",
    "text = normalize_text(raw_text)\n",
    "print(text[:300])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad146a18",
   "metadata": {},
   "source": [
    "### Tokenización a palabras y vectorización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2cf6e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5900,\n",
       " array([3030,    4, 2247, 1800, 2147, 2998,  110, 4104,    6, 1072,   63,\n",
       "           2,    5, 2784,    2,    5, 4105,  355,    6, 4687]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "MAX_VOCAB = None\n",
    "\n",
    "vectorizer = TextVectorization(\n",
    "    standardize=None,          \n",
    "    split='whitespace',\n",
    "    max_tokens=MAX_VOCAB,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=None  \n",
    ")\n",
    "\n",
    "text_ds = tf.data.Dataset.from_tensor_slices([text])\n",
    "vectorizer.adapt(text_ds)\n",
    "\n",
    "vocab = vectorizer.get_vocabulary()              \n",
    "word2id = {w:i for i, w in enumerate(vocab)}     \n",
    "\n",
    "tokens = vectorizer(tf.constant([text])).numpy()[0]  \n",
    "vocab_size = len(vocab)\n",
    "vocab_size, tokens[:20]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3975a09",
   "metadata": {},
   "source": [
    "### Construcción del dataset (ventanas de N palabras → siguiente palabra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51282e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31260, (31240, 20), (31240,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_windows(token_ids: np.ndarray, seq_len: int):\n",
    "    total = len(token_ids) - seq_len\n",
    "    X = np.zeros((total, seq_len), dtype=np.int32)\n",
    "    y = np.zeros((total,), dtype=np.int32)\n",
    "    for i in range(total):\n",
    "        X[i] = token_ids[i: i+seq_len]\n",
    "        y[i] = token_ids[i+seq_len]\n",
    "    return X, y\n",
    "\n",
    "X, y = build_windows(tokens, SEQ_LEN)\n",
    "len(tokens), X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bed75dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 20), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "ds = ds.shuffle(buffer_size=min(10000, len(X))).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79a4ad0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juanp\\Programacion\\Redes-Neuronales-Notebook\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=EMBED_DIM, input_length=SEQ_LEN),\n",
    "    GRU(RNN_UNITS, return_sequences=False),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',   \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528fef01",
   "metadata": {},
   "source": [
    "### Entrenamiento con checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46509ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 47ms/step - accuracy: 0.0990 - loss: 6.7370\n",
      "Epoch 2/20\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 45ms/step - accuracy: 0.1364 - loss: 5.7660\n",
      "Epoch 3/20\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 45ms/step - accuracy: 0.1702 - loss: 5.2071\n",
      "Epoch 4/20\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 45ms/step - accuracy: 0.2025 - loss: 4.6346\n",
      "Epoch 5/20\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 45ms/step - accuracy: 0.2395 - loss: 4.0317\n",
      "Epoch 6/20\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 47ms/step - accuracy: 0.2959 - loss: 3.4182\n",
      "Epoch 7/20\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 45ms/step - accuracy: 0.3934 - loss: 2.8152\n",
      "Epoch 8/20\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 45ms/step - accuracy: 0.4945 - loss: 2.2817\n",
      "Epoch 9/20\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 45ms/step - accuracy: 0.5889 - loss: 1.8454\n",
      "Epoch 10/20\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 45ms/step - accuracy: 0.6711 - loss: 1.4939\n",
      "Epoch 11/20\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 46ms/step - accuracy: 0.7372 - loss: 1.2087\n",
      "Epoch 12/20\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 48ms/step - accuracy: 0.7940 - loss: 0.9682\n",
      "Epoch 13/20\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 46ms/step - accuracy: 0.8447 - loss: 0.7709\n",
      "Epoch 14/20\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 46ms/step - accuracy: 0.8900 - loss: 0.6045\n",
      "Epoch 15/20\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 45ms/step - accuracy: 0.9246 - loss: 0.4634\n",
      "Epoch 16/20\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 45ms/step - accuracy: 0.9519 - loss: 0.3471\n",
      "Epoch 17/20\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 47ms/step - accuracy: 0.9715 - loss: 0.2559\n",
      "Epoch 18/20\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 46ms/step - accuracy: 0.9826 - loss: 0.1898\n",
      "Epoch 19/20\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 46ms/step - accuracy: 0.9907 - loss: 0.1336\n",
      "Epoch 20/20\n",
      "\u001b[1m489/489\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 47ms/step - accuracy: 0.9949 - loss: 0.0931\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('checkpoints_word', exist_ok=True)\n",
    "ckpt = ModelCheckpoint(\n",
    "    filepath='checkpoints_word/weights.{epoch:02d}-{loss:.3f}.keras',\n",
    "    save_weights_only=False,\n",
    "    save_best_only=False\n",
    ")\n",
    "\n",
    "history = model.fit(ds, epochs=EPOCHS, callbacks=[ckpt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d73db34",
   "metadata": {},
   "source": [
    "### Función de muestreo (temperatura) y helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77bcb4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_logits(probs, temperature: float = 1.0):\n",
    "    \"\"\"Muestrea un índice de palabra a partir de una distribución (probs) ajustada por temperatura.\"\"\"\n",
    "    probs = np.asarray(probs).astype(np.float64)\n",
    "    if temperature <= 0:\n",
    "        return int(np.argmax(probs))\n",
    "    logits = np.log(probs + 1e-8) / temperature\n",
    "    exp = np.exp(logits)\n",
    "    adjusted = exp / np.sum(exp)\n",
    "    return int(np.random.choice(len(adjusted), p=adjusted))\n",
    "\n",
    "id2word = vocab\n",
    "\n",
    "def ids_to_text(ids):\n",
    "    return ' '.join(id2word[i] for i in ids if i < len(id2word) and i > 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0627b0",
   "metadata": {},
   "source": [
    "### Generador de texto palabra-por-palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2de90c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, seed_text: str, num_words: int = 50, temperature: float = 1.0):\n",
    "    seed_norm = normalize_text(seed_text)\n",
    "    seed_ids = vectorizer(tf.constant([seed_norm])).numpy()[0].tolist()\n",
    "    seed_ids = [i for i in seed_ids if i != 0]\n",
    "\n",
    "    context = seed_ids[-SEQ_LEN:]\n",
    "    if len(context) < SEQ_LEN:\n",
    "        context = [0]*(SEQ_LEN - len(context)) + context\n",
    "\n",
    "    generated = []\n",
    "\n",
    "    for _ in range(num_words):\n",
    "        x = np.array([context[-SEQ_LEN:]], dtype=np.int32)\n",
    "        probs = model.predict(x, verbose=0)[0]\n",
    "        next_id = sample_from_logits(probs, temperature=temperature)\n",
    "        generated.append(next_id)\n",
    "        context.append(next_id)\n",
    "\n",
    "    return ids_to_text(seed_ids + generated)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0aacf799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- temperature = 0.0 ---\n",
      "en aquel tiempo y muchos otros nvidia nvidia v100 from keras.layers import to_categorical (train_images, train_labels), (test_images, test_labels) = mnist.load_data() train_images = np.random.rand(n) / = 1s 14us/step - loss: 1.5102 - acc: 0.6537 epoch 5/5 60000/60000 [==================] - 1s 13us/step - loss: 1.6978 -\n",
      "\n",
      "--- temperature = 0.7 ---\n",
      "en aquel tiempo y error: traduccion de infraestructuras altamente paralelas. pytorch y la version permite que las mi seguidas a todos los datos de entrenar redes del mundo de programacion general, en esta pagina al escribir las vision por computador. y mas de\n",
      "\n",
      "--- temperature = 1.0 ---\n",
      "en aquel tiempo o data cara. pero si tenemos las gpus, el eje llamado crear la tareas de un tensor negativo, que veremos en mas de dos clases. por eso usaremos lo llamaremos explicado en el capitulo 3 un capitulo definido por lo\n",
      "\n",
      "--- temperature = 1.3 ---\n",
      "en aquel tiempo por dia, son cruciales para considerar mi mayo teoricos donde presenta todos los servicios que cuando solo va a representar los avances en un ordenador con machine learning que han sido ya hoy en 2014 al lector ha venido para\n"
     ]
    }
   ],
   "source": [
    "for temp in [0.0, 0.7, 1.0, 1.3]:\n",
    "    print(f\"\\n--- temperature = {temp} ---\")\n",
    "    print(generate_text(model, seed_text=\"en aquel tiempo\", num_words=40, temperature=temp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
